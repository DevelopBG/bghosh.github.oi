<style>
    .tech-section-title {
    color: #667eea;
    font-size: 1.3em;
    font-weight: 700;
    margin-top: 30px;
    margin-bottom: 15px;
    }

    .technical-skills-list {
        list-style-position: inside;
        padding-left: 0;
        margin: 0;
    }

    .technical-skills-list li {
        color: #495057;
        line-height: 1.8;
        margin-bottom: 15px;
        padding-left: 10px;
    }

    .technical-skills-list li strong {
        color: #667eea;
        font-weight: 600;
    }
    .question-section {
    background: #f0f4ff;
    padding: 20px 25px;
    border-radius: 10px;
    border-left: 4px solid #667eea;
    margin: 20px 0;
    }

    .question-section h4 {
        color: #667eea;
        font-size: 1.15em;
        margin-bottom: 12px;
        font-weight: 700;
    }

    .question-section p {
        color: #495057;
        line-height: 1.8;
        margin: 0;
    }

    .project-image {
        text-align: center;
        margin: 25px 0;
    }

    .project-image img {
        max-width: 50%;
        height: auto;
        border-radius: 10px;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
    }
    
    .projects-container {
        display: flex;
        gap: 30px;
        height: 600px;
    }

    .projects-sidebar {
        width: 350px;
        background: #f8f9fa;
        border-radius: 10px;
        padding: 20px;
        overflow-y: auto;
    }

    .sidebar-title {
        color: #667eea;
        font-size: 1.5em;
        margin-bottom: 20px;
        font-weight: 700;
        padding-bottom: 15px;
        border-bottom: 3px solid #667eea;
    }

    .project-list {
        list-style: none;
        padding: 0;
        margin: 0;
    }

    .project-list-item {
        background: white;
        margin-bottom: 12px;
        padding: 15px 20px;
        border-radius: 8px;
        cursor: pointer;
        border-left: 4px solid transparent;
        transition: all 0.3s ease;
        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.05);
    }

    .project-list-item:hover {
        border-left-color: #764ba2;
        background: #ffffff;
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.15);
        transform: translateX(5px);
    }

    .project-list-item.active {
        border-left-color: #667eea;
        background: linear-gradient(90deg, #667eea15 0%, #ffffff 100%);
        box-shadow: 0 4px 12px rgba(102, 126, 234, 0.2);
    }

    .project-list-item .number {
        display: inline-block;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        width: 30px;
        height: 30px;
        border-radius: 50%;
        text-align: center;
        line-height: 30px;
        font-weight: bold;
        font-size: 0.9em;
        margin-right: 12px;
    }

    .project-list-item.active .number {
        background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    }

    .project-list-item .name {
        color: #495057;
        font-weight: 600;
        font-size: 0.95em;
        line-height: 1.4;
    }

    .project-details {
        flex: 1;
        background: white;
        border-radius: 10px;
        padding: 40px;
        overflow-y: auto;
        box-shadow: 0 5px 20px rgba(0, 0, 0, 0.08);
    }

    .project-content {
        display: none;
    }

    .project-content.active {
        display: block;
        animation: fadeIn 0.4s ease;
    }

    @keyframes fadeIn {
        from {
            opacity: 0;
            transform: translateY(10px);
        }
        to {
            opacity: 1;
            transform: translateY(0);
        }
    }

    .project-header {
        margin-bottom: 30px;
        padding-bottom: 20px;
        border-bottom: 3px solid #e9ecef;
    }

    .project-number-large {
        display: inline-block;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        width: 50px;
        height: 50px;
        border-radius: 50%;
        text-align: center;
        line-height: 50px;
        font-weight: bold;
        font-size: 1.4em;
        margin-bottom: 15px;
    }

    .project-title {
        color: #495057;
        font-size: 1.8em;
        font-weight: 700;
        margin-bottom: 15px;
        line-height: 1.3;
    }

    .project-description {
        color: #6c757d;
        line-height: 1.8;
        font-size: 1.05em;
        margin-bottom: 30px;
    }

    .project-highlights {
        background: #f8f9fa;
        padding: 25px;
        border-radius: 10px;
        border-left: 5px solid #764ba2;
        margin-bottom: 25px;
    }

    .project-highlights h4 {
        color: #764ba2;
        font-size: 1.2em;
        margin-bottom: 15px;
        font-weight: 700;
    }

    .project-highlights ul {
        list-style: none;
        padding: 0;
        margin: 0;
    }

    .project-highlights li {
        padding-left: 25px;
        margin-bottom: 12px;
        position: relative;
        color: #495057;
        line-height: 1.7;
    }

    .project-highlights li::before {
        content: '✓';
        position: absolute;
        left: 0;
        color: #667eea;
        font-weight: bold;
        font-size: 1.2em;
    }

    .project-technologies {
        margin-top: 30px;
    }

    .tech-label {
        color: #667eea;
        font-weight: 700;
        font-size: 1.1em;
        margin-bottom: 15px;
    }

    .tech-tags {
        display: flex;
        flex-wrap: wrap;
        gap: 10px;
    }

    .tech-tag {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 8px 16px;
        border-radius: 20px;
        font-size: 0.9em;
        font-weight: 500;
    }

    .empty-state {
        text-align: center;
        padding: 60px 20px;
        color: #6c757d;
    }

    .empty-state h3 {
        color: #667eea;
        font-size: 1.5em;
        margin-bottom: 10px;
    }

    /* Scrollbar styling */
    .projects-sidebar::-webkit-scrollbar,
    .project-details::-webkit-scrollbar {
        width: 8px;
    }

    .projects-sidebar::-webkit-scrollbar-track,
    .project-details::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 10px;
    }

    .projects-sidebar::-webkit-scrollbar-thumb,
    .project-details::-webkit-scrollbar-thumb {
        background: #667eea;
        border-radius: 10px;
    }

    .projects-sidebar::-webkit-scrollbar-thumb:hover,
    .project-details::-webkit-scrollbar-thumb:hover {
        background: #764ba2;
    }

    @media (max-width: 992px) {
        .projects-container {
            flex-direction: column;
            height: auto;
        }

        .projects-sidebar {
            width: 100%;
            max-height: 300px;
        }

        .project-details {
            min-height: 400px;
        }
    }
</style>

<div class="projects-container">
    <!-- Left Sidebar - Project List -->
    <div class="projects-sidebar">
        <h3 class="sidebar-title">Research Projects</h3>
        <ul class="project-list">
            <li class="project-list-item" data-project="project4">
                <span class="number"></span>
                <span class="name">GrantIQ360 - Compliance Check System</span>
            </li>
            <li class="project-list-item active" data-project="project1">
                <span class="number"></span>
                <span class="name">Machine Learning Security Method</span>
            </li>
            <li class="project-list-item" data-project="project2">
                <span class="number"></span>
                <span class="name">Model Explainability & Visualization</span>
            </li>
            <li class="project-list-item" data-project="project3">
                <span class="number"></span>
                <span class="name">Fine-Grained Category Learning</span>
            </li>
            <li class="project-list-item" data-project="project5">
                <span class="number"></span>
                <span class="name">Lightning Detection & Protection System</span>
            </li>
        </ul>
    </div>

    <!-- Right Side - Project Details -->
    <div class="project-details">
        <!-- Project 1 -->
        <div class="project-content active" id="project1">
            <div class="project-header">
                <div class="project-number-large"></div>
                <h3 class="project-title">Machine Learning Security Method</h3>
            </div>
            
            <p class="project-description">
                In this project, we developed a defense mechanism against adversarial attacks.
            </p>

            <div class="question-section">
                <h4>What is an adversarial attack?</h4>
                <p>
                    Imagine you have a super-smart AI that can recognize animals in pictures. You show it a clear image of a cat, and it confidently says, "That's a cat!". 
                    Now, what if I told you that by adding just a tiny, almost invisible amount of "noise" to the image—something your eyes wouldn't even notice—I could trick the AI into 
                    thinking the cat is actually a dog or even a banana? That's what an adversarial attack does! It's like whispering a secret message that only the AI can hear, confusing it into making mistakes.
                </p>
            </div>

            <p class="project-description">
                We use a novel Targeted Manifold Manipulation (TMM) approach to direct the gradients toward carefully planted traps. 
                The traps are assigned a particular class label (Trapclass or y_Trap) to make the attacks falling in them easily identifiable. 
                Our detection algorithm, TMM defense (denoted as TMM-Def) avoids learning a separate model for attack detection and thus remains 
                semantically aligned with the original classifier. Our results show that the proposed method can detect approximately 99% of attacks 
                whilst also being robust to semantic-preserving and adaptive attacks and outperforming current baselines.
            </p>

            <div class="project-image">
                <img src="assests/images/motivation_tmm.PNG" alt="Motivation of the proposed method">
            </div>
            <p class="project-description">
              Targeted Manifold Manipulation(TMM) of a given classifier, where each data samples are enclosed within a trap-ring having a new class label, y_Trap. 
              The red circle is Trap-ring. Yellow and blue circles represent genuine data points. The dotted black arrows show the attack from Class 1 to Class 2.
              Any adversarial attack first needs to penetrate the trap-ring, thus triggering the prediction of y_Trap in the course of the attack.  
            </p>
            <p class="project-description">
                The adversarial attack detection method (TMM-Def) uses three separate filters, such as Trapclass filter, 
                Entropy filter, and OOD filter, as shown in the above diagram. Details of the implementation is-
            </p>
            <div class="project-image">
                <img src="assests/images/offline-model-detection.PNG" alt="Detection filters">
            </div>

            <div class="project-highlights">
                <h4>Key Achievements</h4>
                <ul>
                    <li>Achieved 99% detection accuracy surpassing existing methods</li>
                    <li>Experimented with various DNN architectures including CNNs and Vision Transformers</li>
                    <li>Validated on benchmark open-source datasets</li>
                    <li>Advanced adversarial defense capabilities</li>
                </ul>
            </div>

            <div class="project-technologies">
                <div class="tech-label">Technologies Used:</div>
                <div class="tech-tags">
                    <span class="tech-tag">Deep Learning</span>
                    <span class="tech-tag">CNN</span>
                    <span class="tech-tag">Vision Transformers</span>
                    <span class="tech-tag">PyTorch</span>
                    <span class="tech-tag">Computer Vision</span>
                </div>
            </div>
        </div>

        <!-- Project 2 -->
        <div class="project-content" id="project2">
            <div class="project-header">
                <div class="project-number-large"></div>
                <h3 class="project-title">Model Explainability & Visualization</h3>
            </div>
            
            <p class="project-description">
                As AI technology continues to evolve, its models are becoming more intricate and are being deployed across a wide range of domains, including social media analytics, financial services, and medical diagnostics. 
                Given the growing reliance on AI-driven decision-making, ensuring transparency and explainability of model predictions is of paramount importance. 
                This necessity has led to the emergence of Explainable AI (XAI), which aims to provide insights into model behavior and foster trust in AI systems. 
                One approach to avail model explainability is the retrieval of similar instances from the training dataset that are most relevant to a given prediction.
            </p>
            <p class="project-description">
               We identify the nearest neighbors by selecting points from the exemplar set (often the training set or a curated version of that) that exhibit high activation under this backdoor. 
            </p>
            <p class="project-description">
               We developed a modified backdoor technique that generates query-specific orthogonal triggers which are responsible for the local distortion to the manifold where the query sample is located in the manifold. 
            </p>
            <div class="project-image">
                <img src="assests/images/intro1.jpeg" alt="Introduction1" width="200"><img src="assests/images/intro2.jpeg" alt="introduction2" width="200"><img src="assests/images/intro3.jpeg" alt="introduction4" width="200">
            </div>
            <p class="project-description">
               The first image shows a pre-trained binary classifier (theta) distinguishing between two classes, Class1 and Class2, and all the training samples, plotted in red and blue to represent their classes respectively, 
               and a query point (from testset), positioned within the class Class1, has been marked in the figure too. 
               The second figure showcases the change in the decision surface of the model (theta prime) after fine-tuning, a distinct uplift is introduced in the region where the query sample was mapped. The green cap of the mountain represents the dummy class. 
               The last figure shows the retrieval process once we get the TMM model (i.e. theta_prime). Neighbours can then be identified by their affinity to the dummy class when added with the trigger, as shown.
            </p>
            <div class="project-highlights">
                <h4>Key Achievements</h4>
                <ul>
                    <li>Enhanced model transparency through visual explanations</li>
                    <li>Identified decision-critical regions in input data</li>
                    <li>Developed feature relevance mapping techniques</li>
                    <li>Facilitated model debugging through intuitive saliency mapping</li>
                </ul>
            </div>

            <div class="project-technologies">
                <div class="tech-label">Technologies Used:</div>
                <div class="tech-tags">
                    <span class="tech-tag">Model Interpretation</span>
                    <span class="tech-tag">Saliency Mapping</span>
                    <span class="tech-tag">CNN</span>
                    <span class="tech-tag">Transformers</span>
                    <span class="tech-tag">Visualization</span>
                </div>
            </div>
        </div>

        <!-- Project 3 -->
        <div class="project-content" id="project3">
            <div class="project-header">
                <div class="project-number-large"></div>
                <h3 class="project-title">Fine-Grained Category Learning</h3>
            </div>
            
            <p class="project-description">
                Humans excel at combining orthogonal concepts for fine-grained classifications, whereas machines often struggle with this task. For example, a machine learning model trained to recognize cars may have difficulty identifying a specific subset, such as red cars, unless it has been explicitly trained on that distinction. 
                Text-based concept learning offers a potential solution, it requires a large volume of annotated data and may only generalize to unseen concept combinations at a foundational model scale. 
                To the best of our knowledge, no purely visual-domain solution exists that can learn from just a few examples of individual concepts let alone from their combinations.
            </p>
            <p class="project-description">
                We introduce three types of concepts: primary, secondary, and composite. The primary concept refers to the object class in the pre-trained model (e.g., car), the secondary concept represents a finer-grained attribute within the primary concept (e.g., red), and the composite concept is the combination of both (e.g., red car). 
                Our approach formulates a contrastive learning problem, utilizing backdoors as a mechanism to extract composite concepts.
            </p>
            <div class="project-image">
                <img src="assests/images/method_training_v1.PNG">
                <img src="assests/images/method_testing.PNG">
            </div>

            <div class="project-highlights">
                <h4>Key Achievements</h4>
                <ul>
                    <li>Minimal supervision requirement for training</li>
                    <li>Recognition of unseen concept combinations</li>
                    <li>No reliance on annotated textual descriptions</li>
                    <li>Reduced dependency on large datasets</li>
                </ul>
            </div>

            <div class="project-technologies">
                <div class="tech-label">Technologies Used:</div>
                <div class="tech-tags">
                    <span class="tech-tag">Few-Shot Learning</span>
                    <span class="tech-tag">Transfer Learning</span>
                    <span class="tech-tag">Deep Learning</span>
                    <span class="tech-tag">Computer Vision</span>
                </div>
            </div>
        </div>

        <!-- Project 4 -->
        <div class="project-content" id="project4">
            <div class="project-header">
                <div class="project-number-large"></div>
                <h3 class="project-title">GrantIQ360 - Compliance Check System</h3>
            </div>
            
            <p class="project-description">
                AI-Powered Grant Compliance & Analysis Platform Full-Stack Serverless Application with Multi-Model AI Integration
            </p>
            <p class="project-description">
                GrantIQ360, an enterprise-grade AI-powered compliance analysis platform that revolutionizes grant proposal evaluation. Built a sophisticated serverless architecture on AWS integrating multiple Large Language Models (Gemini 2.5 Pro, GPT-4, Claude Sonnet 4) for intelligent document processing. 
                Implemented robust security with JWT authentication, role-based access control (RBAC), and comprehensive audit logging. Developed advanced features including PDF annotation with pypdf, intelligent document chunking, checkpoint-based processing for crash recovery, and real-time credit management. Integrated Stripe payment processing and Clerk authentication for seamless user experience. 
                The platform processes complex grant guidelines and proposals, generating detailed compliance reports with gap analysis and actionable recommendations, achieving 15-second average analysis time for 50-page documents.
            </p>
            <h2 class="tech-section-title"> Technical Skills Demonstrated</h2>
            <ol class="technical-skills-list">
                <li class="technical-skills-list">
                    <strong>Large Language Models (LLMs):</strong> Integrated multiple LLMs (Gemini 2.5 Pro, GPT-4, Claude Sonnet 4) for diverse NLP tasks including document summarization, compliance checking, and recommendation generation.
                </li>
                <li class="technical-skills-list">
                    <strong>Serverless Architecture:</strong> Designed and implemented a scalable serverless backend using AWS Lambda, DynamoDB, and S3 for efficient document processing and storage.
                </li>
                <li class="technical-skills-list">
                    <strong>Authentication & Security:</strong> Developed secure authentication workflows using JWT and Clerk, implementing role-based access control (RBAC) for user management.
                </li>
                <li class="technical-skills-list">
                    <strong>PDF Processing:</strong> Utilized pypdf for advanced PDF parsing, annotation, and validation to extract and analyze document content.
                </li>
                <li class="technical-skills-list">
                    <strong>Resilient Processing Pipelines:</strong> Created checkpoint-based processing to handle large documents, ensuring crash recovery and efficient resource utilization.
                </li>
                <li class="technical-skills-list">
                    <strong>Payment Integration:</strong> Integrated Stripe for seamless payment processing and credit management within the platform.
                </li>
                <li class="technical-skills-list">
                    <strong>Frontend Development:</strong> Built a responsive React frontend for user interaction, document upload, and report visualization.
                </li>
                <li class="technical-skills-list">
                    <strong>Audit Logging:</strong> Implemented comprehensive audit logging for tracking user actions and system events.
                </li>
                <li class="technical-skills-list">
                    <strong>Performance Optimization:</strong> Achieved an average analysis time of 15 seconds for 50-page documents through efficient coding and resource management.
                </li>
                <li class="technical-skills-list">
                    <strong>Cloud Services:</strong> Leveraged various AWS services for hosting, storage, and computing needs.
                </li>
                <li class="technical-skills-list">
                    <strong>Agile Development:</strong> Employed agile methodologies for iterative development, testing, and deployment.
                </li>
                <li class="technical-skills-list">
                    <strong>Team Collaboration:</strong> Worked closely with cross-functional teams including AI researchers, backend and frontend developers, and product managers to deliver a high-quality product.
                </li>
                <li class="technical-skills-list">
                    <strong>Documentation & Reporting:</strong> Created detailed technical documentation and user guides for platform features and functionalities.
                </li>                        
            </ol>
            </p>
            <div class="project-image">
                <img src="assests/images/grantiq1.png" alt="Motivation of the proposed method">
                <img src="assests/images/grantiq2.png" alt="Motivation of the proposed method">
                <img src="assests/images/grantiq3.png" alt="Motivation of the proposed method">
                <img src="assests/images/grantiq4.png" alt="Motivation of the proposed method">
                <img src="assests/images/grantiq5.png" alt="Motivation of the proposed method">
            </div>
            <div class="project-highlights">
                <h4>Key Achievements</h4>
                <ul>
                    <li>Integrated LLM (Gemini-2.5, Claude Sonnet) into research platform</li>
                    <li>Developed autonomous LLM-based agents with retrieval tools</li>
                    <li>Built scalable serverless backend (AWS Lambda, DynamoDB, S3)</li>
                    <li>Implemented secure authentication workflows (JWT, RBAC)</li>
                    <li>Created PDF parsing and validation pipelines</li>
                </ul>
            </div>

            <div class="project-technologies">
                <div class="tech-label">Technologies Used:</div>
                <div class="tech-tags">
                    <span class="tech-tag">LLM</span>
                    <span class="tech-tag">AWS</span>
                    <span class="tech-tag">React</span>
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">LangChain</span>
                    <span class="tech-tag">DynamoDB</span>
                </div>
            </div>
        </div>

        <!-- Project 5 -->
        <div class="project-content" id="project5">
            <div class="project-header">
                <div class="project-number-large"></div>
                <h3 class="project-title">Lightning Detection & Protection System</h3>
            </div>
            
            <p class="project-description">
                This project is for the detection and prediction system of local lightning. Different types of environmental parameters have an impact on lightning strikes. 
                These parameters values are very volatile and location-specific. Some of the dominant parameters, like electric field gradient, electric field strength, atmospheric pressure, etc. have been considered to predict lightning strikes. 
                For initial detection, AS3935 IC has been implemented with some modification which detects lightning strokes within some specific range. 
                A Fuzzy inference system has been developed so that the prediction can be done using the dominant parameter values without having a large prior dataset of lightning strikes of any specified location.
            </p>
            <div class="project-image">
                <img src="assests/images/lightning_detection.jpg" alt="Lightning Detection System">
            </div>
            <div class="project-highlights">
                <h4>Key Achievements</h4>
                <ul>
                    <li>Achieved benchmark results in lightning detection</li>
                    <li>Published in IEEE international scientific conference</li>
                    <li>Collaborated with PhD researchers</li>
                    <li>Practical application in protection systems</li>
                </ul>
            </div>

            <div class="project-technologies">
                <div class="tech-label">Technologies Used:</div>
                <div class="tech-tags">
                    <span class="tech-tag">Python</span>
                    <span class="tech-tag">MATLAB</span>
                    <span class="tech-tag">Machine Learning</span>
                    <span class="tech-tag">Signal Processing</span>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    // Project navigation functionality
    (function() {
        // Use setTimeout to ensure DOM is ready when loaded via fetch
        setTimeout(function() {
            const projectItems = document.querySelectorAll('.project-list-item');
            const projectContents = document.querySelectorAll('.project-content');

            projectItems.forEach(item => {
                item.addEventListener('click', function() {
                    const projectId = this.getAttribute('data-project');

                    // Remove active class from all items and contents
                    projectItems.forEach(i => i.classList.remove('active'));
                    projectContents.forEach(c => c.classList.remove('active'));

                    // Add active class to clicked item and corresponding content
                    this.classList.add('active');
                    document.getElementById(projectId).classList.add('active');
                });
            });
        }, 100);
    })();
</script>